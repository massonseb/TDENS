{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interstate-closer",
   "metadata": {},
   "source": [
    "## Subject:\n",
    "In addition to the SST (sst.mnmean.nc), I uploded on my GiHub these datasets to complete the description of the El-Nino phenomenon. \n",
    " - precip.mon.mean.nc\n",
    " - msl_era5.nc\n",
    " - lwdn.nc\n",
    " - ewss_era5.nc\n",
    " - sla_aviso.nc\n",
    " \n",
    "Using basic xarray commands as seen in TD1, could you describe which variables are in these NetCDF files? \n",
    "What is the spatial and temporal domain and resolution? \n",
    "What is the origin of the data? Are they based on \"observations\" or models? Why do I use quotes in \"observations\"?\n",
    "\n",
    "Why did I choose these variables to illustrate El-Nino? Before doing any analyse/plot, which patterns do you expect to see in the interannual variability of these variables in the tropical Pacific? And why?\n",
    "\n",
    "Choose 1 atmospheric and 1 oceanic dataset among the 5th datasets.\n",
    "\n",
    "Following what was done in TD2, compute the regression and the correlation maps of these data on Nino 3.4 **SST** index.\n",
    "Explain the units of the maps and how to read them. What is the conceptual difference between these 2 maps?\n",
    "Give a physical interpretation of the results.\n",
    "\n",
    "Following what was done in TD3, compute the EOFS of 1 atmospheric and 1 oceanic dataset (change dataset if possible). Plot the % of explained variance by the first 10 EOFS. Comment this plot. \n",
    "\n",
    "For one of the dataset, compute the variance of each PCs. Compute covariance between the 2 PCs. Compute correlation between the 2 EOFs (see bellow for details). Which results should/do you get? \n",
    "\n",
    "Plot the first 2 EOFS, and their PCs. Next, compute the correlation of each of the first 2 PCs with Nino3.4 **SST** index. Comment the results for the first EOF/PC. If you choose u10_era5.nc or slp.mnmean.nc as atmospheric data, you may exclude values outside of 25째S-25째N to exclude high-latitude signal and facilitate the analyse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-miniature",
   "metadata": {},
   "source": [
    "## Some advises/information for your python scripts:\n",
    "\n",
    " - [There is a pdf file](https://github.com/massonseb/TDENS/blob/main/help_exam.pdf) which explains how to use this notebook to create your own notebook.\n",
    " - If you have problems with memory size limitation, reduce the memory footprint (see TD1) by extracting the data over a smaller domain (exclude higher latitudes and/or exclude parts of the Atlantic and/or Indian Oceans). You can also restart the python kernel and re-execute only a part if the commands to limit the creation of intermediate arrays which you don't need but use memory space. \n",
    " - When using sel(lon=...) to select the longitude, check the longitude ranges (0 -> 360 or -180 -> 180) and values (0, 1,...) or (0.5, 1.5...). Same story when selecting the latitude and check if latitudes are defined in increasing or decreasing order.\n",
    " - Don't forget to look at dataset and variable attributes do get information about the datasets. Beware: to limit the size of the datasets, I regridded some of the datasets on a 1째x1째 grid. Attributes related to the grid definition and resolution may be outdated -> look at the lon/lat values themselves\n",
    " - Check what you are doing by plotting your (intermediate) data and their related information (such as their shape)\n",
    " ```python\n",
    "# to get general information on your DataSet or DataArray\n",
    "data\n",
    "# to get the shape of the variable xxx\n",
    "data.xxx.shape\n",
    "# for a quick plot of the variable xxx\n",
    "data.xxx.mean(dim='time').plot()\n",
    "data.xxx.isem(time=0).plot()\n",
    " ```\n",
    " - You will need to compute interannual anomalies of your dataset. You must first remove the linear trend on each point and next remove a monthly climatology (see TD1).\n",
    " - For the correlation and linear regression with Nino 3.4 (see TD2), make sure that you selected the common period between your dataset and Nino3.4 SST index (even if xarray might do it automatically).\n",
    " - The datasets do not have any mask file available to built the weights (as it was the case for the SST). Select 1 time step (any one) and plot a map of the data you chose to visualize it. Some data are defined everywhere, other have a specific value over the continents (e.g nan which means Not a Number). You can [np.where](https://numpy.org/doc/stable/reference/generated/numpy.where.html) to build the mask.\n",
    " ```python\n",
    "# select 1 time step of the variable \"xxx\" \n",
    "data = xr.open_dataset('my_file.nc')\n",
    "mask = data.xxx.isel(time=0)\n",
    "# to test if mask is containing nan\n",
    "print(mask.all().data)  # return True is there is no nan values\n",
    "# to build the mask based on existing nan value\n",
    "mask.data = np.where(np.isnan(mask.data), 0., 1.)\n",
    "# to build the mask based on existing missing value\n",
    "missing_value = ...  \n",
    "mask.data = np.where(mask.data == missing_value, 0., 1.)\n",
    " ```\n",
    "In all cases, plot a map of your weights to check if there is no error!\n",
    " ```python\n",
    "weights.plot()\n",
    " ``` \n",
    " - Weighted spatial covariance is not (yet) directly available in xarray... There is one method to compute the weighted covariance between X an Y:\n",
    " ```python \n",
    "x = ...\n",
    "y = ...\n",
    "xw = x.weighted(weights)\n",
    "yw = y.weighted(weights)\n",
    "z = ( x - xw.mean() ) * ( y - yw.mean() )\n",
    "zw = z.weighted(weights2)\n",
    "cov = zw.mean()\n",
    " ``` \n",
    " - The first time step of lwdn.nc is quite strange... I did not change it. It was like that when I downloaded it. => Always have, a least, a quick look at the data you are manipulating! You can, for example, remove this date with:\n",
    " ```python\n",
    "data.drop_isel(time=0)\n",
    " ``` \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
